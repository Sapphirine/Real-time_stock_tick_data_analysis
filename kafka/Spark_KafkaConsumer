#remove aws source, use archieve.ubuntu instead
#sudo sed -i 's/us-east-1\.ec2\.//g' /etc/apt/sources.list
#sudo apt-get install build-essential
#sudo apt-get install default-jre

wget http://apache.mirrors.pair.com/kafka/0.9.0.0/kafka_2.11-0.9.0.0.tgz
tar -xzf kafka_2.11-0.9.0.0.tgz
cd kafka_2.11-0.9.0.0

#after ZK and server start
#create topic
bin/kafka-topics.sh --create --zookeeper 172.31.10.74:2181 --replication-factor 1 --partitions 1 --topic test
bin/kafka-console-consumer.sh --zookeeper 172.31.10.74:2181 --topic test --from-beginning

#bin/kafka-console-consumer.sh --zookeeper 172.31.10.74:2181 --topic test --from-beginning
#bin/kafka-console-producer.sh --broker-list 172.31.10.74:9092 --topic test

###########################################################################################
now install spark, with script
AWS_Ubuntu_Installation.rtf
###########################################################################################

#fisrt of all, silence info by:
#http://stackoverflow.com/questions/25193488/how-to-turn-off-info-logging-in-pyspark

bin/spark-submit --jars spark-streaming-kafka-assembly_2.10-1.6.1.jar test.py 172.31.10.74:2181 test

bin/spark-submit --jars spark-streaming-kafka-assembly_2.10-1.6.1.jar examples/src/main/python/streaming/direct_kafka_wordcount.py 172.31.10.74:2181 test

